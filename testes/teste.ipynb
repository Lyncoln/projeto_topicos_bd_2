{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2ae27671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType, sum, max, col, concat, lit\n",
    "import sys\n",
    "import os\n",
    "# setup to work around with pandas udf\n",
    "# see answers here https://stackoverflow.com/questions/58458415/pandas-scalar-udf-failing-illegalargumentexception\n",
    "\n",
    "#os.environ[\"ARROW_PRE_0_15_IPC_FORMAT\"] = \"1\"\n",
    "from fbprophet import Prophet\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2c2e7baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an output schema\n",
    "schema = StructType([\n",
    "        StructField(\"store\", StringType(), True),\n",
    "        StructField(\"item\", StringType(), True),\n",
    "        StructField(\"ds\", DateType(), True),\n",
    "        StructField(\"yhat\", DoubleType(), True)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "649d9d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetHolidays():\n",
    "    playoffs = pd.DataFrame({\n",
    "        'holiday': 'playoff',\n",
    "        'ds': pd.to_datetime(['2013-01-12', '2013-07-12', '2013-12-24',\n",
    "                              '2014-01-12', '2014-07-12', '2014-07-19',\n",
    "                              '2014-07-02', '2014-12-24', '2015-07-11', '2015-12-24',\n",
    "                              '2016-07-17', '2016-07-24', '2016-07-07',\n",
    "                              '2016-07-24', '2016-12-24', '2017-07-17', '2017-07-24',\n",
    "                              '2017-07-07', '2017-12-24']),\n",
    "        'lower_window': 0,\n",
    "        'upper_window': 2}\n",
    "    )\n",
    "    superbowls = pd.DataFrame({\n",
    "        'holiday': 'superbowl',\n",
    "        'ds': pd.to_datetime(['2013-01-01', '2013-01-21', '2013-02-14', '2013-02-18',\n",
    "                              '2013-05-27', '2013-07-04', '2013-09-02', '2013-10-14', '2013-11-11', '2013-11-28',\n",
    "                              '2013-12-25', '2014-01-01', '2014-01-20', '2014-02-14', '2014-02-17',\n",
    "                              '2014-05-26', '2014-07-04', '2014-09-01', '2014-10-13', '2014-11-11', '2014-11-27',\n",
    "                              '2014-12-25', '2015-01-01', '2015-01-19', '2015-02-14', '2015-02-16',\n",
    "                              '2015-05-25', '2015-07-03', '2015-09-07', '2015-10-12', '2015-11-11', '2015-11-26',\n",
    "                              '2015-12-25', '2016-01-01', '2016-01-18', '2016-02-14', '2016-02-15',\n",
    "                              '2016-05-30', '2016-07-04', '2016-09-05', '2016-10-10', '2016-11-11', '2016-11-24',\n",
    "                              '2016-12-25', '2017-01-02', '2017-01-16', '2017-02-14', '2017-02-20',\n",
    "                              '2017-05-29', '2017-07-04', '2017-09-04', '2017-10-09', '2017-11-10', '2017-11-23',\n",
    "                              '2017-12-25', '2018-01-01', '2018-01-15', '2018-02-14', '2018-02-19'\n",
    "                              ]),\n",
    "        'lower_window': 0,\n",
    "        'upper_window': 3,\n",
    "    })\n",
    "\n",
    "    holidays = pd.concat((playoffs, superbowls))\n",
    "    return holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0074cbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "def fit_pandas_udf(df):\n",
    "    \"\"\"\n",
    "    :param df: Dataframe (train + test data)\n",
    "    :return: predictions as defined in the output schema\n",
    "    \"\"\"\n",
    "\n",
    "    def train_fitted_prophet(df, cutoff):\n",
    "        # train\n",
    "        ts_train = (df\n",
    "                    .query('date <= @cutoff')\n",
    "                    .rename(columns={'date': 'ds', 'sales': 'y'})\n",
    "                    .sort_values('ds')\n",
    "                    )\n",
    "        # test\n",
    "        ts_test = (df\n",
    "                   .query('date > @cutoff')\n",
    "                   .rename(columns={'date': 'ds', 'sales': 'y'})\n",
    "                   .sort_values('ds')\n",
    "                   .assign(ds=lambda x: pd.to_datetime(x[\"ds\"]))\n",
    "                   .drop('y', axis=1)\n",
    "                   )\n",
    "\n",
    "        print(ts_test.columns)\n",
    "        # get holidays\n",
    "        holidays = GetHolidays()\n",
    "        # init model\n",
    "        m = Prophet(yearly_seasonality=True,\n",
    "                    weekly_seasonality=True,\n",
    "                    daily_seasonality=True,\n",
    "                    holidays=holidays)\n",
    "        m.fit(ts_train)\n",
    "\n",
    "        # to date\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        # at this step we predict the future and we get plenty of additional columns be cautious\n",
    "        ts_hat = (m.predict(ts_test)[[\"ds\", \"yhat\"]]\n",
    "                  .assign(ds=lambda x: pd.to_datetime(x[\"ds\"]))\n",
    "                  ).merge(ts_test, on=[\"ds\"], how=\"left\")  # merge to retrieve item and store index\n",
    "        # debug\n",
    "        # print(ts_hat)\n",
    "        return pd.DataFrame(ts_hat, columns=schema.fieldNames())\n",
    "\n",
    "    return train_fitted_prophet(df, cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4d355efd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'apply'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5367/39740078.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     global_predictions = (df\n\u001b[0m\u001b[1;32m     32\u001b[0m                           \u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_pandas_udf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                           )\n",
      "\u001b[0;32m~/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1641\u001b[0m         \"\"\"\n\u001b[1;32m   1642\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1643\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m   1644\u001b[0m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[1;32m   1645\u001b[0m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'apply'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    spark = (SparkSession\n",
    "             .builder\n",
    "             .appName(\"forecasting\")\n",
    "             .getOrCreate()\n",
    "             #.config('spark.sql.execution.arrow.enable', 'true')\n",
    "             )\n",
    "\n",
    "    # read input data from :https://www.kaggle.com/c/demand-forecasting-kernels-only/data\n",
    "    data_train = (spark\n",
    "                  .read\n",
    "                  .format(\"csv\")\n",
    "                  .option('header', 'true')\n",
    "                  .load('Downloads/train.csv')\n",
    "                  )\n",
    "\n",
    "    data_test = (spark\n",
    "                 .read\n",
    "                 .format(\"csv\")\n",
    "                 .option('header', 'true')\n",
    "                 .load('Downloads/test.csv')\n",
    "                 .drop('id')\n",
    "                 )\n",
    "    # max train date\n",
    "    cutoff = data_train.select(max(col('date'))).collect()[0][0]\n",
    "    # add sales none col to match with union\n",
    "    data_test = data_test.withColumn('sales', lit(None))\n",
    "    # concat train test\n",
    "    df = (data_train.union(data_test)).sort(col('date'))\n",
    "    # fit\n",
    "    global_predictions = (df\n",
    "                          .groupBy(\"store\", \"item\")\n",
    "                          .apply(fit_pandas_udf)\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0b6ac178",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Index(['ds', 'store', 'item'], dtype='object')                      (0 + 1) / 1]\n",
      "Initial log joint probability = -39.0279\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       3162.09   0.000665731       51.6977           1           1      140   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     180       3163.07   3.51836e-05       44.3314   7.183e-07       0.001      301  LS failed, Hessian reset \n",
      "     199       3163.08   2.73223e-07       63.0232      0.1486      0.6146      339   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     202       3163.08   1.91591e-07       48.0371      0.6716      0.6716      342   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Index(['ds', 'store', 'item'], dtype='object')\n",
      "Initial log joint probability = -16.1685\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       4503.86   0.000788211       89.3245           1           1      135   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     171       4504.32   0.000140468       220.988   1.638e-06       0.001      266  LS failed, Hessian reset \n",
      "     199       4504.45   0.000229668       71.9442      0.7598      0.7598      298   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     241       4504.48   0.000140506       201.363   1.411e-06       0.001      385  LS failed, Hessian reset \n",
      "     299       4504.52   3.25319e-06       51.8252      0.1476      0.1476      454   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       4504.79     0.0108912       176.603           1           1      575   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     453       4505.12   9.66436e-08       53.4855      0.4171      0.4171      652   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Index(['ds', 'store', 'item'], dtype='object')\n",
      "Initial log joint probability = -25.1332\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      86        3571.9   0.000122809       97.6943   8.318e-07       0.001      161  LS failed, Hessian reset \n",
      "      99        3572.1   0.000207127        75.134           1           1      179   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     117       3572.12   7.09984e-05       47.6906   7.868e-07       0.001      246  LS failed, Hessian reset \n",
      "     137       3572.13   2.95583e-07        53.391      0.3297           1      281   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Index(['ds', 'store', 'item'], dtype='object')\n",
      "Initial log joint probability = -40.7059\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      83        3737.2   8.72786e-05       92.0398   8.121e-07       0.001      149  LS failed, Hessian reset \n",
      "      99       3737.27   0.000183939       83.5522           1           1      170   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     195       3737.51   0.000202402       112.869   2.259e-06       0.001      323  LS failed, Hessian reset \n",
      "     199       3737.53   2.79347e-05       94.4475      0.2268      0.2268      328   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     279       3737.61   3.22369e-08       65.1301    0.007813      0.1414      433   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Index(['ds', 'store', 'item'], dtype='object')\n",
      "Initial log joint probability = -41.7865\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99        3471.9     0.0035961        156.05           1           1      130   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     170       3472.17   0.000182235       107.719    2.22e-06       0.001      262  LS failed, Hessian reset \n",
      "     199       3472.18   4.38162e-06       74.0973           1           1      301   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     277       3472.35   0.000150617        99.698   1.922e-06       0.001      446  LS failed, Hessian reset \n",
      "     299        3472.5   6.68657e-05       74.1954      0.3176           1      474   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       3472.51   2.46094e-06       75.8254       0.343           1      601   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     422       3472.52    4.9193e-05       84.1366   4.592e-07       0.001      671  LS failed, Hessian reset \n",
      "     466       3472.53   1.29706e-07       72.2821      0.4534      0.4534      730   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Index(['ds', 'store', 'item'], dtype='object')\n",
      "Initial log joint probability = -31.6487\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       4042.35   0.000404536       114.091       0.798       0.798      129   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     118       4042.45   0.000310937        250.27   2.925e-06       0.001      186  LS failed, Hessian reset \n",
      "     169       4042.58   3.45981e-05       82.8317     4.2e-07       0.001      295  LS failed, Hessian reset \n",
      "     199       4042.59   7.44515e-06       78.6463      0.7399      0.7399      330   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     236       4042.59   2.65918e-07        73.413      0.3293           1      377   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----------+------------------+\n",
      "|store|item|        ds|              yhat|\n",
      "+-----+----+----------+------------------+\n",
      "|    1|  41|2018-01-01|15.471495870405267|\n",
      "|    1|  41|2018-01-02|17.020638776276527|\n",
      "|    1|  41|2018-01-03|16.221878717845797|\n",
      "|    1|  41|2018-01-04|17.238218764781866|\n",
      "|    1|  41|2018-01-05|19.092043298687635|\n",
      "|    1|  41|2018-01-06|20.670652324286028|\n",
      "|    1|  41|2018-01-07|20.986448774112684|\n",
      "|    1|  41|2018-01-08|12.765461785764138|\n",
      "|    1|  41|2018-01-09|15.389144465061227|\n",
      "|    1|  41|2018-01-10|15.507868271424892|\n",
      "+-----+----+----------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "global_predictions.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0846313a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-12-31'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "275f7db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----+-----+\n",
      "|      date|store|item|sales|\n",
      "+----------+-----+----+-----+\n",
      "|2013-01-01|    2|  16|   15|\n",
      "|2013-01-01|   10|  15|   51|\n",
      "|2013-01-01|    4|  14|   43|\n",
      "|2013-01-01|    6|  15|   38|\n",
      "|2013-01-01|    7|  14|   25|\n",
      "|2013-01-01|    5|  14|   22|\n",
      "|2013-01-01|    1|  16|   14|\n",
      "|2013-01-01|    2|  15|   65|\n",
      "|2013-01-01|   10|  13|   46|\n",
      "|2013-01-01|    1|  15|   42|\n",
      "|2013-01-01|    5|  15|   31|\n",
      "|2013-01-01|    8|  50|   45|\n",
      "|2013-01-01|    3|  15|   61|\n",
      "|2013-01-01|    4|  15|   46|\n",
      "|2013-01-01|    2|  14|   33|\n",
      "|2013-01-01|   10|  50|   33|\n",
      "|2013-01-01|    9|  14|   26|\n",
      "|2013-01-01|   10|  16|   20|\n",
      "|2013-01-01|   10|  14|   30|\n",
      "|2013-01-01|    9|  50|   36|\n",
      "+----------+-----+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 83:===================>                                      (2 + 4) / 6]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
